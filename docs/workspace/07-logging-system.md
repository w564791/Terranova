# Workspaceæ¨¡å— - æ—¥å¿—ç³»ç»Ÿ

> **æ–‡æ¡£ç‰ˆæœ¬**: v1.0  
> **åˆ›å»ºæ—¥æœŸ**: 2025-10-09  
> **çŠ¶æ€**: ç¬¬ä¸€ç‰ˆåŸºç¡€æ—¥å¿—ï¼Œç¬¬äºŒç‰ˆå®Œæ•´ç³»ç»Ÿ

## ğŸ“˜ æ¦‚è¿°

æ—¥å¿—ç³»ç»Ÿè´Ÿè´£è®°å½•ã€å­˜å‚¨å’ŒæŸ¥è¯¢Workspaceå’Œä»»åŠ¡æ‰§è¡Œçš„æ‰€æœ‰æ—¥å¿—ã€‚ç¬¬ä¸€ç‰ˆå®ç°åŸºç¡€æ—¥å¿—åŠŸèƒ½ï¼Œç¬¬äºŒç‰ˆæ‰©å±•åˆ°Elasticsearchã€Lokiã€S3ç­‰å¤šåç«¯æ”¯æŒã€‚

## ğŸ¯ ç¬¬ä¸€ç‰ˆï¼šåŸºç¡€æ—¥å¿—ç³»ç»Ÿ

### æ—¥å¿—ç±»å‹

**4ç§æ—¥å¿—ç±»å‹**:
1. **ä»»åŠ¡æ—¥å¿—**: Plan/Applyæ‰§è¡Œæ—¥å¿—
2. **ç³»ç»Ÿæ—¥å¿—**: å¹³å°ç³»ç»Ÿæ—¥å¿—
3. **å®¡è®¡æ—¥å¿—**: ç”¨æˆ·æ“ä½œå®¡è®¡
4. **é”™è¯¯æ—¥å¿—**: é”™è¯¯å’Œå¼‚å¸¸

### æ—¥å¿—ç»“æ„

**ç»Ÿä¸€æ ¼å¼**:
```json
{
  "timestamp": "2025-10-09T10:00:00.123Z",
  "level": "info",
  "source": "task_worker",
  "workspace_id": 1,
  "task_id": 123,
  "message": "Executing terraform plan",
  "metadata": {
    "execution_mode": "local",
    "terraform_version": "1.6.0"
  }
}
```

### æ—¥å¿—çº§åˆ«

```go
type LogLevel string

const (
    LogLevelDebug   LogLevel = "debug"
    LogLevelInfo    LogLevel = "info"
    LogLevelWarning LogLevel = "warning"
    LogLevelError   LogLevel = "error"
    LogLevelFatal   LogLevel = "fatal"
)
```

### æ•°æ®æ¨¡å‹

```go
type TaskLog struct {
    ID          uint      `json:"id"`
    WorkspaceID uint      `json:"workspace_id"`
    TaskID      uint      `json:"task_id"`
    Level       LogLevel  `json:"level"`
    Source      string    `json:"source"`
    Message     string    `json:"message"`
    Metadata    JSONB     `json:"metadata"`
    CreatedAt   time.Time `json:"created_at"`
}
```

### æ—¥å¿—è®°å½•

**Loggeræ¥å£**:
```go
type Logger interface {
    Debug(msg string, fields ...Field)
    Info(msg string, fields ...Field)
    Warning(msg string, fields ...Field)
    Error(msg string, fields ...Field)
    Fatal(msg string, fields ...Field)
}

type Field struct {
    Key   string
    Value interface{}
}
```

**ä½¿ç”¨ç¤ºä¾‹**:
```go
logger.Info("Starting terraform plan",
    Field{"workspace_id", workspaceID},
    Field{"task_id", taskID},
    Field{"execution_mode", "local"},
)
```

### æ—¥å¿—å­˜å‚¨

**ç¬¬ä¸€ç‰ˆï¼šPostgreSQL**
- ç®€å•å®ç°
- æ˜“äºæŸ¥è¯¢
- é€‚åˆä¸­å°è§„æ¨¡

**å­˜å‚¨ç­–ç•¥**:
- ä¿ç•™æœ€è¿‘30å¤©
- è‡ªåŠ¨æ¸…ç†æ—§æ—¥å¿—
- å‹ç¼©å½’æ¡£

```go
func (s *LogService) CleanOldLogs() error {
    cutoff := time.Now().AddDate(0, 0, -30)
    return s.db.Where("created_at < ?", cutoff).
        Delete(&TaskLog{}).Error
}
```

## ğŸ“Š APIæ¥å£

### æ—¥å¿—æŸ¥è¯¢

```http
# è·å–ä»»åŠ¡æ—¥å¿—
GET /api/v1/workspaces/:id/tasks/:task_id/logs
?level=info&limit=100&offset=0

# å®æ—¶æ—¥å¿—æµï¼ˆWebSocketï¼‰
WS /api/v1/workspaces/:id/tasks/:task_id/logs/stream

# ä¸‹è½½æ—¥å¿—
GET /api/v1/workspaces/:id/tasks/:task_id/logs/download

# æœç´¢æ—¥å¿—
POST /api/v1/workspaces/:id/logs/search
{
  "query": "error",
  "start_time": "2025-10-09T00:00:00Z",
  "end_time": "2025-10-09T23:59:59Z",
  "level": "error"
}
```

### å“åº”æ ¼å¼

```json
{
  "logs": [
    {
      "timestamp": "2025-10-09T10:00:00Z",
      "level": "info",
      "message": "Terraform plan completed",
      "metadata": {}
    }
  ],
  "total": 150,
  "has_more": true
}
```

## ğŸš€ ç¬¬äºŒç‰ˆï¼šå®Œæ•´æ—¥å¿—ç³»ç»Ÿ

### å¤šåç«¯æ”¯æŒ

#### 1. Elasticsearch

**ç”¨é€”**: å…¨æ–‡æœç´¢å’Œåˆ†æ

**ç´¢å¼•ç»“æ„**:
```json
{
  "mappings": {
    "properties": {
      "timestamp": {"type": "date"},
      "level": {"type": "keyword"},
      "workspace_id": {"type": "integer"},
      "task_id": {"type": "integer"},
      "message": {"type": "text"},
      "metadata": {"type": "object"}
    }
  }
}
```

**æŸ¥è¯¢ç¤ºä¾‹**:
```json
{
  "query": {
    "bool": {
      "must": [
        {"match": {"message": "error"}},
        {"range": {"timestamp": {"gte": "now-1h"}}}
      ]
    }
  }
}
```

#### 2. Loki

**ç”¨é€”**: è½»é‡çº§æ—¥å¿—èšåˆ

**æ ‡ç­¾**:
```
{workspace="prod", task="123", level="error"}
```

**LogQLæŸ¥è¯¢**:
```
{workspace="prod"} |= "error" | json | line_format "{{.message}}"
```

#### 3. S3

**ç”¨é€”**: é•¿æœŸå½’æ¡£

**å­˜å‚¨è·¯å¾„**:
```
s3://logs-bucket/workspaces/{workspace_id}/tasks/{task_id}/{date}/logs.json.gz
```

**å½’æ¡£ç­–ç•¥**:
- 30å¤©åå½’æ¡£åˆ°S3
- å‹ç¼©å­˜å‚¨
- ç”Ÿå‘½å‘¨æœŸç®¡ç†

#### 4. HTTPSè½¬å‘

**ç”¨é€”**: è½¬å‘åˆ°å¤–éƒ¨ç³»ç»Ÿ

**é…ç½®**:
```yaml
log_forwarding:
  - name: splunk
    type: https
    endpoint: https://splunk.example.com/services/collector
    headers:
      Authorization: "Splunk xxx"
    batch_size: 100
    flush_interval: 10s
```

### æ—¥å¿—è·¯ç”±

**è·¯ç”±é…ç½®**:
```yaml
log_backends:
  - name: postgres
    type: postgres
    retention_days: 30
    levels: [debug, info, warning, error, fatal]
    
  - name: elasticsearch
    type: elasticsearch
    endpoint: http://elasticsearch:9200
    index: workspace-logs
    levels: [warning, error, fatal]
    
  - name: loki
    type: loki
    endpoint: http://loki:3100
    levels: [info, warning, error, fatal]
    
  - name: s3-archive
    type: s3
    bucket: logs-archive
    retention_days: 365
    levels: [error, fatal]
```

## ğŸ” æ—¥å¿—åˆ†æ

### å®æ—¶ç›‘æ§

**ç›‘æ§æŒ‡æ ‡**:
- é”™è¯¯ç‡
- æ—¥å¿—é‡
- å“åº”æ—¶é—´
- å­˜å‚¨ä½¿ç”¨

**å‘Šè­¦è§„åˆ™**:
```yaml
alerts:
  - name: high_error_rate
    condition: error_rate > 10%
    duration: 5m
    action: send_notification
    
  - name: log_storage_full
    condition: storage_usage > 90%
    action: cleanup_old_logs
```

### æ—¥å¿—èšåˆ

**èšåˆæŸ¥è¯¢**:
```sql
SELECT 
    DATE_TRUNC('hour', created_at) as hour,
    level,
    COUNT(*) as count
FROM task_logs
WHERE workspace_id = 1
GROUP BY hour, level
ORDER BY hour DESC
```

### æ—¥å¿—å¯è§†åŒ–

**Grafana Dashboard**:
- æ—¥å¿—é‡è¶‹åŠ¿
- é”™è¯¯ç‡å›¾è¡¨
- æ—¥å¿—çº§åˆ«åˆ†å¸ƒ
- Topé”™è¯¯æ¶ˆæ¯

## ğŸ”§ å®ç°ç¤ºä¾‹

### LogService

```go
type LogService struct {
    db       *gorm.DB
    backends []LogBackend
}

type LogBackend interface {
    Write(log *TaskLog) error
    Query(filter LogFilter) ([]TaskLog, error)
    Name() string
}

func (s *LogService) Write(log *TaskLog) error {
    // å†™å…¥æ‰€æœ‰åç«¯
    for _, backend := range s.backends {
        go func(b LogBackend) {
            if err := b.Write(log); err != nil {
                log.Printf("Failed to write to %s: %v", b.Name(), err)
            }
        }(backend)
    }
    return nil
}

func (s *LogService) StreamLogs(taskID uint, ch chan<- *TaskLog) error {
    // å®æ—¶æµå¼ä¼ è¾“æ—¥å¿—
    ticker := time.NewTicker(time.Second)
    defer ticker.Stop()
    
    lastID := uint(0)
    
    for range ticker.C {
        var logs []TaskLog
        err := s.db.Where("task_id = ? AND id > ?", taskID, lastID).
            Order("id ASC").
            Limit(100).
            Find(&logs).Error
        
        if err != nil {
            return err
        }
        
        for _, log := range logs {
            ch <- &log
            lastID = log.ID
        }
    }
    
    return nil
}
```

### WebSocketæ—¥å¿—æµ

```go
func (c *TaskController) StreamLogs(ctx *gin.Context) {
    ws, err := upgrader.Upgrade(ctx.Writer, ctx.Request, nil)
    if err != nil {
        return
    }
    defer ws.Close()
    
    taskID := ctx.GetUint("task_id")
    logChan := make(chan *TaskLog, 100)
    
    go logService.StreamLogs(taskID, logChan)
    
    for log := range logChan {
        if err := ws.WriteJSON(log); err != nil {
            break
        }
    }
}
```

## ğŸ“ æœ€ä½³å®è·µ

### 1. æ—¥å¿—æ ¼å¼
- ä½¿ç”¨ç»“æ„åŒ–æ—¥å¿—ï¼ˆJSONï¼‰
- åŒ…å«ä¸Šä¸‹æ–‡ä¿¡æ¯
- ç»Ÿä¸€æ—¶é—´æ ¼å¼ï¼ˆISO 8601ï¼‰
- æ·»åŠ å…³è”ID

### 2. æ€§èƒ½ä¼˜åŒ–
- å¼‚æ­¥å†™å…¥
- æ‰¹é‡å¤„ç†
- ç¼“å†²é˜Ÿåˆ—
- å‹ç¼©å­˜å‚¨

### 3. å®‰å…¨æ€§
- æ•æ„Ÿä¿¡æ¯è„±æ•
- è®¿é—®æ§åˆ¶
- åŠ å¯†ä¼ è¾“
- å®¡è®¡è¿½è¸ª

### 4. è¿ç»´
- å®šæœŸæ¸…ç†
- ç›‘æ§å‘Šè­¦
- å¤‡ä»½æ¢å¤
- å®¹é‡è§„åˆ’

---

**ç›¸å…³æ–‡æ¡£**:
- [00-overview.md](./00-overview.md) - æ€»è§ˆå’Œæ¶æ„
- [04-task-workflow.md](./04-task-workflow.md) - ä»»åŠ¡å·¥ä½œæµ
- [06-notification-system.md](./06-notification-system.md) - é€šçŸ¥ç³»ç»Ÿ
